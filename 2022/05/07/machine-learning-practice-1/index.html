<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta name="google-site-verification" content="SEuuKcxiY0Z6R9aAPIZyU5Y9rFqpgO9gKES--zhFX24" />
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.2/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"wangxchun.github.io","root":"/","images":"/images","scheme":"Pisces","version":"8.2.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜尋...","empty":"我們無法找到任何有關 ${query} 的搜索結果","hits_time":"${hits} 找到 ${time} 個結果","hits":"找到 ${hits} 個結果"}};
  </script>
<meta name="description" content="一、前言 Objectives:  Solve a regression problem with deep neural networks (DNN). Understand basic DNN training tips. Familiarize yourself with PyTorch.   二、引入 python 库 123456789101112131415161718192021&amp;">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习实战 --（1）regression">
<meta property="og:url" content="https://wangxchun.github.io/2022/05/07/machine-learning-practice-1/index.html">
<meta property="og:site_name" content="Nathan自强不息">
<meta property="og:description" content="一、前言 Objectives:  Solve a regression problem with deep neural networks (DNN). Understand basic DNN training tips. Familiarize yourself with PyTorch.   二、引入 python 库 123456789101112131415161718192021&amp;">
<meta property="og:locale" content="zh_TW">
<meta property="article:published_time" content="2022-05-07T12:36:29.000Z">
<meta property="article:modified_time" content="2022-05-08T07:37:51.942Z">
<meta property="article:author" content="Nathan Wang">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://wangxchun.github.io/2022/05/07/machine-learning-practice-1/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-TW'
  };
</script>
<title>机器学习实战 --（1）regression | Nathan自强不息</title>
  




  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切換導航欄" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Nathan自强不息</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Be Friend with Time</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首頁</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>關於</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>標籤</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分類</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>歸檔</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目錄
        </li>
        <li class="sidebar-nav-overview">
          本站概要
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E3%80%81%E5%89%8D%E8%A8%80"><span class="nav-text"> 一、前言 </span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C%E3%80%81%E5%BC%95%E5%85%A5%20-python-%20%E5%BA%93"><span class="nav-text"> 二、引入 python 库 </span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89%E3%80%81Utility-Functions"><span class="nav-text"> 三、Utility Functions</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Start-training"><span class="nav-text">Start training!</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Plot-learning-curves-with-tensorboard-optional"><span class="nav-text">Plot learning curves with tensorboard (optional)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Testing"><span class="nav-text">Testing</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Reference"><span class="nav-text">Reference</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Nathan Wang"
      src="/img/avatar.jpg">
  <p class="site-author-name" itemprop="name">Nathan Wang</p>
  <div class="site-description" itemprop="description">機器學習 / C++ / 投資 / 台灣景點</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">232</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">39</span>
        <span class="site-state-item-name">分類</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">303</span>
        <span class="site-state-item-name">標籤</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/wangxchun" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;wangxchun" rel="noopener" target="_blank"><i class="GitHub fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:nathanwang0205@outlook.com" title="E-Mail → mailto:nathanwang0205@outlook.com" rel="noopener" target="_blank"><i class="e-mail fa-fw"></i>E-Mail</a>
      </span>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://wangxchun.github.io/2022/05/07/machine-learning-practice-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/avatar.jpg">
      <meta itemprop="name" content="Nathan Wang">
      <meta itemprop="description" content="機器學習 / C++ / 投資 / 台灣景點">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Nathan自强不息">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          机器学习实战 --（1）regression
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-05-07 20:36:29" itemprop="dateCreated datePublished" datetime="2022-05-07T20:36:29+08:00">2022-05-07</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新於</span>
        <time title="修改時間：2022-05-08 15:37:51" itemprop="dateModified" datetime="2022-05-08T15:37:51+08:00">2022-05-08</time>
      </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h3 id="一、前言"><a href="# 一、前言" class="headerlink" title="一、前言"></a> 一、前言 </h3><p>Objectives:</p>
<ul>
<li>Solve a regression problem with deep neural networks (DNN).</li>
<li>Understand basic DNN training tips.</li>
<li>Familiarize yourself with PyTorch.</li>
</ul>
<h3 id="二、引入 -python- 库"><a href="# 二、引入 -python- 库" class="headerlink" title="二、引入 python 库"></a> 二、引入 python 库 </h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;# Import packages&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Numerical Operations</span></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Reading/Writing Data</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"></span><br><span class="line"><span class="comment"># For Progress Bar</span></span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="comment"># Pytorch</span></span><br><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader, random_split</span><br><span class="line"></span><br><span class="line"><span class="comment"># For plotting learning curve</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br></pre></td></tr></table></figure>
<h3 id="三、Utility-Functions"><a href="# 三、Utility-Functions" class="headerlink" title="三、Utility Functions"></a> 三、Utility Functions</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">same_seed</span> (<span class="params">seed</span>):</span> </span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;Fixes random number generator seeds for reproducibility.&#x27;&#x27;&#x27;</span></span><br><span class="line">    torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line">    torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br><span class="line">    np.random.seed (seed)</span><br><span class="line">    torch.manual_seed (seed)</span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available ():</span><br><span class="line">        torch.cuda.manual_seed_all (seed)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_valid_split</span> (<span class="params">data_set, valid_ratio, seed</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;Split provided training data into training set and validation set&#x27;&#x27;&#x27;</span></span><br><span class="line">    valid_set_size = <span class="built_in">int</span> (valid_ratio * <span class="built_in">len</span> (data_set)) </span><br><span class="line">    train_set_size = <span class="built_in">len</span> (data_set) - valid_set_size</span><br><span class="line">    train_set, valid_set = random_split (data_set, [train_set_size, valid_set_size], generator=torch.Generator ().manual_seed (seed))</span><br><span class="line">    <span class="keyword">return</span> np.array (train_set), np.array (valid_set)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span> (<span class="params">test_loader, model, device</span>):</span></span><br><span class="line">    model.<span class="built_in">eval</span> () <span class="comment"># Set your model to evaluation mode.</span></span><br><span class="line">    preds = []</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> tqdm (test_loader):</span><br><span class="line">        x = x.to (device)                        </span><br><span class="line">        <span class="keyword">with</span> torch.no_grad ():                   </span><br><span class="line">            pred = model (x)                     </span><br><span class="line">            preds.append (pred.detach ().cpu ())   </span><br><span class="line">    preds = torch.cat (preds, dim=<span class="number">0</span>).numpy ()  </span><br><span class="line">    <span class="keyword">return</span> preds</span><br></pre></td></tr></table></figure>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"> 设置 torch.backends.cudnn.benchmark=<span class="literal">True</span> 将会让程序在开始时花费一点额外时间，为整个网络的每个卷积层搜索最适合它的卷积实现算法，进而实现网络的加速。适用场景是网络结构固定（不是动态变化的），网络的输入形状（包括 batch size，图片大小，输入的通道）是不变的，其实也就是一般情况下都比较适用。反之，如果卷积层的设置一直变化，将会导致程序不停地做优化，反而会耗费更多的时间。</span><br><span class="line"></span><br><span class="line">torch.backends.cudnn.deterministic=<span class="literal">True</span></span><br><span class="line"> 每次返回的卷积算法将是确定的，即默认算法。cudnn 中包含很多卷积算法。基于 GEMM (General Matrix Multiply) 的，基于 FFT 的，基于 Winograd 算法的等等。</span><br><span class="line"></span><br><span class="line"> 设置 seed () 里的数字就相当于设置了一个盛有随机数的 “聚宝盆”，一个数字代表一个 “聚宝盆”，当我们在 seed（）的括号里设置相同的 seed，“聚宝盆” 就是一样的，从里面拿出的随机数就会相同。</span><br><span class="line"></span><br><span class="line">&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;rng&lt;/span&gt; ():&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; i &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;built_in&quot;&gt;range&lt;/span&gt; (&lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        np.random.seed (&lt;span class=&quot;number&quot;&gt;123&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;built_in&quot;&gt;print&lt;/span&gt; (np.random.rand (&lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;rng ()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;gt;&amp;gt;&amp;gt;[&lt;span class=&quot;number&quot;&gt;0.69646919&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.28613933&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.22685145&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.55131477&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   [&lt;span class=&quot;number&quot;&gt;0.69646919&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.28613933&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.22685145&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.55131477&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   [&lt;span class=&quot;number&quot;&gt;0.69646919&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.28613933&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.22685145&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.55131477&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   [&lt;span class=&quot;number&quot;&gt;0.69646919&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.28613933&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.22685145&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.55131477&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   [&lt;span class=&quot;number&quot;&gt;0.69646919&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.28613933&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.22685145&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.55131477&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;rng_n&lt;/span&gt; ():&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    np.random.seed (&lt;span class=&quot;number&quot;&gt;123&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; i &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;built_in&quot;&gt;range&lt;/span&gt; (&lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;built_in&quot;&gt;print&lt;/span&gt; (np.random.rand (&lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;rng_n ()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;gt;&amp;gt;&amp;gt;[&lt;span class=&quot;number&quot;&gt;0.69646919&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.28613933&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.22685145&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.55131477&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   [&lt;span class=&quot;number&quot;&gt;0.71946897&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.42310646&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.9807642&lt;/span&gt;  &lt;span class=&quot;number&quot;&gt;0.68482974&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   [&lt;span class=&quot;number&quot;&gt;0.4809319&lt;/span&gt;  &lt;span class=&quot;number&quot;&gt;0.39211752&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.34317802&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.72904971&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   [&lt;span class=&quot;number&quot;&gt;0.43857224&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.0596779&lt;/span&gt;  &lt;span class=&quot;number&quot;&gt;0.39804426&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.73799541&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;   [&lt;span class=&quot;number&quot;&gt;0.18249173&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.17545176&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.53155137&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0.53182759&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</span><br><span class="line">&lt;p&gt; 在神经网络中，参数默认是进行随机初始化的。如果不设置的话每次训练时的初始化都是随机的，导致结果不确定。如果设置初始化，则每次初始化都是固定的。&lt;br&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; args.seed &lt;span class=&quot;keyword&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;literal&quot;&gt;None&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    random.seed (args.seed) &lt;span class=&quot;comment&quot;&gt;#&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    torch.manual_seed (args.seed)  &lt;span class=&quot;comment&quot;&gt;# 为 CPU 设置种子用于生成随机数，以使得结果是确定的   　　 torch.cuda.manual_seed (args.seed) #为当前 GPU 设置随机种子；&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    cudnn.deterministic = &lt;span class=&quot;literal&quot;&gt;True&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 如果使用多个 GPU，应该使用 torch.cuda.manual_seed_all () 为所有的 GPU 设置种子。&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;</span><br><span class="line">&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;torch.utils.data.random_split (dataset, lengths, generator=&amp;lt;torch._C.Generator &lt;span class=&quot;built_in&quot;&gt;object&lt;/span&gt;&amp;gt;)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</span><br><span class="line">&lt;p&gt; 在 CPU 中设置生成随机数的种子，并返回一个 torch.Generator 对象。当设置的种子固定下来的时候，之后依次 pytorch 生成的随机数序列也被固定下来。需要注意的是当只调用 torch.manual_seed () 一次时并不能生成相同的随机数序列。如果想要得到相同的随机数序列就需要每次产生随机数的时候都要调用一下 torch.manual_seed ()。&lt;br&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; torch&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;torch.manual_seed (&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;lt;torch._C.Generator &lt;span class=&quot;built_in&quot;&gt;object&lt;/span&gt; at &lt;span class=&quot;number&quot;&gt;0x000001EB8F3A1918&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class=&quot;built_in&quot;&gt;print&lt;/span&gt; (torch.randn (&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tensor ([[&lt;span class=&quot;number&quot;&gt;0.3923&lt;/span&gt;, -&lt;span class=&quot;number&quot;&gt;0.2236&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        [-&lt;span class=&quot;number&quot;&gt;0.3195&lt;/span&gt;, -&lt;span class=&quot;number&quot;&gt;1.2050&lt;/span&gt;]])&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;span class=&quot;built_in&quot;&gt;print&lt;/span&gt; (torch.randn (&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tensor ([[&lt;span class=&quot;number&quot;&gt;1.0445&lt;/span&gt;, -&lt;span class=&quot;number&quot;&gt;0.6332&lt;/span&gt;],&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        [&lt;span class=&quot;number&quot;&gt;0.5731&lt;/span&gt;,  &lt;span class=&quot;number&quot;&gt;0.5409&lt;/span&gt;]])&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;</span><br><span class="line">&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/357075502&quot;&gt;Pytorch：model.train () 和 model.eval () 用法和区别 &lt;/a&gt;&lt;/p&gt;</span><br><span class="line">&lt;h3 id=&quot; 四、Dataset”&quot;&gt;&lt;a href=&quot;# 四、Dataset”&quot; class=&quot;headerlink&quot; title=&quot; 四、Dataset”&quot;&gt;&lt;/a&gt; 四、Dataset”&lt;/h3&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;COVID19Dataset&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;Dataset&lt;/span&gt;):&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;string&quot;&gt;&amp;#x27;&amp;#x27;&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;    x: Features.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;    y: Targets, if none, do prediction.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;    &amp;#x27;&amp;#x27;&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;__init__&lt;/span&gt;(&lt;span class=&quot;params&quot;&gt;self, x, y=&lt;span class=&quot;literal&quot;&gt;None&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; y &lt;span class=&quot;keyword&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;literal&quot;&gt;None&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            self.y = y&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            self.y = torch.FloatTensor (y)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.x = torch.FloatTensor (x)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;__getitem__&lt;/span&gt;(&lt;span class=&quot;params&quot;&gt;self, idx&lt;/span&gt;):&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; self.y &lt;span class=&quot;keyword&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;literal&quot;&gt;None&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; self.x [idx]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; self.x [idx], self.y [idx]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;__len__&lt;/span&gt;(&lt;span class=&quot;params&quot;&gt;self&lt;/span&gt;):&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;built_in&quot;&gt;len&lt;/span&gt; (self.x)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</span><br><span class="line">&lt;h3 id=&quot; 五、Neural-Network-Model&quot;&gt;&lt;a href=&quot;# 五、Neural-Network-Model&quot; class=&quot;headerlink&quot; title=&quot; 五、Neural Network Model&quot;&gt;&lt;/a&gt; 五、Neural Network Model&lt;/h3&gt;&lt;p&gt;Try out different model architectures by modifying the class below.&lt;/p&gt;</span><br><span class="line">&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;My_Model&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;nn.Module&lt;/span&gt;):&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;__init__&lt;/span&gt;(&lt;span class=&quot;params&quot;&gt;self, input_dim&lt;/span&gt;):&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;built_in&quot;&gt;super&lt;/span&gt; (My_Model, self).__init__()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;comment&quot;&gt;# &lt;span class=&quot;doctag&quot;&gt;TODO:&lt;/span&gt; modify model&amp;#x27;s structure, be aware of dimensions. &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.layers = nn.Sequential (&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            nn.Linear (input_dim, &lt;span class=&quot;number&quot;&gt;16&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            nn.ReLU (),&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            nn.Linear (&lt;span class=&quot;number&quot;&gt;16&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;8&lt;/span&gt;),&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            nn.ReLU (),&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            nn.Linear (&lt;span class=&quot;number&quot;&gt;8&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        )&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;forward&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;self, x&lt;/span&gt;):&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        x = self.layers (x)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        x = x.squeeze (&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;) &lt;span class=&quot;comment&quot;&gt;# (B, 1) -&amp;gt; (B)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; x&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</span><br><span class="line">&lt;p&gt;Pytorch Tensor 的通道排序：[batch, channel, height, weight]&lt;br&gt;&lt;a href=&quot;https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html&quot;&gt;pytorch lenet&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://blog.csdn.net/jokerxsy/article/details/108614661&quot;&gt;nn.Conv1d\nn.Conv2d 以及 groups\dilation 参数的理解 &lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://www.jianshu.com/p/c1232e47661f&quot;&gt;PyTorch 教程 - 3：PyTorch 中神经网络的构建与训练基础 &lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://blog.csdn.net/qq_26442553/article/details/81775449&quot;&gt;Python 多继承与 super 使用详解 &lt;/a&gt;&lt;/p&gt;</span><br><span class="line">&lt;p&gt;&lt;img src=&quot;./machineLearning-1/1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;</span><br><span class="line">&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/york1996/article/details/81949843&quot;&gt;PyTorch 中 view 的用法 &lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/27382990&quot;&gt; 图像基本操作 torchvision.transforms&lt;/a&gt;&lt;/p&gt;</span><br><span class="line">&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;main&lt;/span&gt; ():&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    transform = transforms.Compose (&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        [transforms.ToTensor (),&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;         transforms.Normalize ((&lt;span class=&quot;number&quot;&gt;0.5&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;0.5&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;0.5&lt;/span&gt;), (&lt;span class=&quot;number&quot;&gt;0.5&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;0.5&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;0.5&lt;/span&gt;))])&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;comment&quot;&gt;# 50000 张训练图片 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;comment&quot;&gt;# 第一次使用时要将 download 设置为 True 才会自动去下载数据集 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    train_set = torchvision.datasets.CIFAR10 (root=&lt;span class=&quot;string&quot;&gt;&amp;#x27;./data&amp;#x27;&lt;/span&gt;, train=&lt;span class=&quot;literal&quot;&gt;True&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                                             download=&lt;span class=&quot;literal&quot;&gt;False&lt;/span&gt;, transform=transform)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    train_loader = torch.utils.data.DataLoader (train_set, batch_size=&lt;span class=&quot;number&quot;&gt;36&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                                               shuffle=&lt;span class=&quot;literal&quot;&gt;True&lt;/span&gt;, num_workers=&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;comment&quot;&gt;# 10000 张验证图片 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;comment&quot;&gt;# 第一次使用时要将 download 设置为 True 才会自动去下载数据集 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    val_set = torchvision.datasets.CIFAR10 (root=&lt;span class=&quot;string&quot;&gt;&amp;#x27;./data&amp;#x27;&lt;/span&gt;, train=&lt;span class=&quot;literal&quot;&gt;False&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                                           download=&lt;span class=&quot;literal&quot;&gt;False&lt;/span&gt;, transform=transform)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    val_loader = torch.utils.data.DataLoader (val_set, batch_size=&lt;span class=&quot;number&quot;&gt;5000&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                                             shuffle=&lt;span class=&quot;literal&quot;&gt;False&lt;/span&gt;, num_workers=&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    val_data_iter = &lt;span class=&quot;built_in&quot;&gt;iter&lt;/span&gt; (val_loader)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    val_image, val_label = val_data_iter.&lt;span class=&quot;built_in&quot;&gt;next&lt;/span&gt; ()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    ...&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</span><br><span class="line">&lt;p&gt;&lt;img src=&quot;./machineLearning-1/photo2.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;</span><br><span class="line">&lt;h3 id=&quot; 六、Feature-Selection&quot;&gt;&lt;a href=&quot;# 六、Feature-Selection&quot; class=&quot;headerlink&quot; title=&quot; 六、Feature Selection&quot;&gt;&lt;/a&gt; 六、Feature Selection&lt;/h3&gt;&lt;p&gt;Choose features you deem useful by modifying the function below.&lt;/p&gt;</span><br><span class="line">&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;select_feat&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;train_data, valid_data, test_data, select_all=&lt;span class=&quot;literal&quot;&gt;True&lt;/span&gt;&lt;/span&gt;):&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;string&quot;&gt;&amp;#x27;&amp;#x27;&amp;#x27;Selects useful features to perform regression&amp;#x27;&amp;#x27;&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    y_train, y_valid = train_data [:,-&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;], valid_data [:,-&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    raw_x_train, raw_x_valid, raw_x_test = train_data [:,:-&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;], valid_data [:,:-&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;], test_data&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; select_all:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        feat_idx = &lt;span class=&quot;built_in&quot;&gt;list&lt;/span&gt; (&lt;span class=&quot;built_in&quot;&gt;range&lt;/span&gt; (raw_x_train.shape [&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;]))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt;:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        feat_idx = [&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;4&lt;/span&gt;] &lt;span class=&quot;comment&quot;&gt;# &lt;span class=&quot;doctag&quot;&gt;TODO:&lt;/span&gt; Select suitable feature columns.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; raw_x_train [:,feat_idx], raw_x_valid [:,feat_idx], raw_x_test [:,feat_idx], y_train, y_valid&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</span><br><span class="line">&lt;h3 id=&quot; 六、Training-Loop&quot;&gt;&lt;a href=&quot;# 六、Training-Loop&quot; class=&quot;headerlink&quot; title=&quot; 六、Training Loop&quot;&gt;&lt;/a&gt; 六、Training Loop&lt;/h3&gt;&lt;p&gt;(1) batchsize：批大小。在深度学习中，一般采用 SGD 训练，即每次训练在训练集中取 batchsize 个样本训练；&lt;br&gt;(2) iteration：1 个 iteration 等于使用 batchsize 个样本训练一次；&lt;br&gt;(3) epoch：1 个 epoch 等于使用训练集中的全部样本训练一次；&lt;/p&gt;</span><br><span class="line">&lt;p&gt; 举个例子，训练集有 1000 个样本，batchsize=10，那么，&lt;br&gt; 训练完整个样本集需要：100 次 iteration，1 次 epoch。&lt;/p&gt;</span><br><span class="line">&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;66&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;trainer&lt;/span&gt; (&lt;span class=&quot;params&quot;&gt;train_loader, valid_loader, model, config, device&lt;/span&gt;):&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    criterion = nn.MSELoss (reduction=&lt;span class=&quot;string&quot;&gt;&amp;#x27;mean&amp;#x27;&lt;/span&gt;) &lt;span class=&quot;comment&quot;&gt;# Define your loss function, do not modify this.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;comment&quot;&gt;# Define your optimization algorithm. &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;comment&quot;&gt;# &lt;span class=&quot;doctag&quot;&gt;TODO:&lt;/span&gt; Please check https://pytorch.org/docs/stable/optim.html to get more available algorithms.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;comment&quot;&gt;# &lt;span class=&quot;doctag&quot;&gt;TODO:&lt;/span&gt; L2 regularization (optimizer (weight decay...) or implement by your self).&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    optimizer = torch.optim.SGD (model.parameters (), lr=config [&lt;span class=&quot;string&quot;&gt;&amp;#x27;learning_rate&amp;#x27;&lt;/span&gt;], momentum=&lt;span class=&quot;number&quot;&gt;0.9&lt;/span&gt;) &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    writer = SummaryWriter () &lt;span class=&quot;comment&quot;&gt;# Writer of tensoboard.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;not&lt;/span&gt; os.path.isdir (&lt;span class=&quot;string&quot;&gt;&amp;#x27;./models&amp;#x27;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        os.mkdir (&lt;span class=&quot;string&quot;&gt;&amp;#x27;./models&amp;#x27;&lt;/span&gt;) &lt;span class=&quot;comment&quot;&gt;# Create directory of saving models.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    n_epochs, best_loss, step, early_stop_count = config [&lt;span class=&quot;string&quot;&gt;&amp;#x27;n_epochs&amp;#x27;&lt;/span&gt;], math.inf, &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; epoch &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;built_in&quot;&gt;range&lt;/span&gt; (n_epochs):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        model.train () &lt;span class=&quot;comment&quot;&gt;# Set your model to train mode.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        loss_record = []&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;comment&quot;&gt;# tqdm is a package to visualize your training progress.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        train_pbar = tqdm (train_loader, position=&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;, leave=&lt;span class=&quot;literal&quot;&gt;True&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; x, y &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; train_pbar:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            optimizer.zero_grad ()               &lt;span class=&quot;comment&quot;&gt;# Set gradient to zero.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            x, y = x.to (device), y.to (device)   &lt;span class=&quot;comment&quot;&gt;# Move your data to device. &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            pred = model (x)             &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            loss = criterion (pred, y)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            loss.backward ()                     &lt;span class=&quot;comment&quot;&gt;# Compute gradient (backpropagation).&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            optimizer.step ()                    &lt;span class=&quot;comment&quot;&gt;# Update parameters.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            step += &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            loss_record.append (loss.detach ().item ())&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;comment&quot;&gt;# Display current epoch number and loss on tqdm progress bar.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            train_pbar.set_description (&lt;span class=&quot;string&quot;&gt;f&amp;#x27;Epoch [&lt;span class=&quot;subst&quot;&gt;&amp;#123;epoch+&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&amp;#125;&lt;/span&gt;/&lt;span class=&quot;subst&quot;&gt;&amp;#123;n_epochs&amp;#125;&lt;/span&gt;]&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            train_pbar.set_postfix (&amp;#123;&lt;span class=&quot;string&quot;&gt;&amp;#x27;loss&amp;#x27;&lt;/span&gt;: loss.detach ().item ()&amp;#125;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        mean_train_loss = &lt;span class=&quot;built_in&quot;&gt;sum&lt;/span&gt; (loss_record)/&lt;span class=&quot;built_in&quot;&gt;len&lt;/span&gt; (loss_record)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        writer.add_scalar (&lt;span class=&quot;string&quot;&gt;&amp;#x27;Loss/train&amp;#x27;&lt;/span&gt;, mean_train_loss, step)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        model.&lt;span class=&quot;built_in&quot;&gt;eval&lt;/span&gt; () &lt;span class=&quot;comment&quot;&gt;# Set your model to evaluation mode.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        loss_record = []&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; x, y &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; valid_loader:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            x, y = x.to (device), y.to (device)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;keyword&quot;&gt;with&lt;/span&gt; torch.no_grad ():&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                pred = model (x)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                loss = criterion (pred, y)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            loss_record.append (loss.item ())&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        mean_valid_loss = &lt;span class=&quot;built_in&quot;&gt;sum&lt;/span&gt; (loss_record)/&lt;span class=&quot;built_in&quot;&gt;len&lt;/span&gt; (loss_record)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;built_in&quot;&gt;print&lt;/span&gt; (&lt;span class=&quot;string&quot;&gt;f&amp;#x27;Epoch [&lt;span class=&quot;subst&quot;&gt;&amp;#123;epoch+&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&amp;#125;&lt;/span&gt;/&lt;span class=&quot;subst&quot;&gt;&amp;#123;n_epochs&amp;#125;&lt;/span&gt;]: Train loss: &lt;span class=&quot;subst&quot;&gt;&amp;#123;mean_train_loss:&lt;span class=&quot;number&quot;&gt;.4&lt;/span&gt;f&amp;#125;&lt;/span&gt;, Valid loss: &lt;span class=&quot;subst&quot;&gt;&amp;#123;mean_valid_loss:&lt;span class=&quot;number&quot;&gt;.4&lt;/span&gt;f&amp;#125;&lt;/span&gt;&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        writer.add_scalar (&lt;span class=&quot;string&quot;&gt;&amp;#x27;Loss/valid&amp;#x27;&lt;/span&gt;, mean_valid_loss, step)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; mean_valid_loss &amp;lt; best_loss:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            best_loss = mean_valid_loss&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            torch.save (model.state_dict (), config [&lt;span class=&quot;string&quot;&gt;&amp;#x27;save_path&amp;#x27;&lt;/span&gt;]) &lt;span class=&quot;comment&quot;&gt;# Save your best model&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;built_in&quot;&gt;print&lt;/span&gt; (&lt;span class=&quot;string&quot;&gt;&amp;#x27;Saving model with loss &amp;#123;:.3f&amp;#125;...&amp;#x27;&lt;/span&gt;.&lt;span class=&quot;built_in&quot;&gt;format&lt;/span&gt; (best_loss))&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            early_stop_count = &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt;: &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            early_stop_count += &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; early_stop_count &amp;gt;= config [&lt;span class=&quot;string&quot;&gt;&amp;#x27;early_stop&amp;#x27;&lt;/span&gt;]:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;built_in&quot;&gt;print&lt;/span&gt; (&lt;span class=&quot;string&quot;&gt;&amp;#x27;\nModel is not improving, so we halt the training session.&amp;#x27;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</span><br><span class="line">&lt;h2 id=&quot; 七、Configurations&quot;&gt;&lt;a href=&quot;# 七、Configurations&quot; class=&quot;headerlink&quot; title=&quot; 七、Configurations&quot;&gt;&lt;/a&gt; 七、Configurations&lt;/h2&gt;&lt;p&gt;&lt;code&gt;config&lt;/code&gt; contains hyper-parameters for training and the path to save your model.&lt;/p&gt;</span><br><span class="line">&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;device = &lt;span class=&quot;string&quot;&gt;&amp;#x27;cuda&amp;#x27;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; torch.cuda.is_available () &lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&amp;#x27;cpu&amp;#x27;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;config = &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;string&quot;&gt;&amp;#x27;seed&amp;#x27;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;5201314&lt;/span&gt;,      &lt;span class=&quot;comment&quot;&gt;# Your seed number, you can pick your lucky number. :)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;string&quot;&gt;&amp;#x27;select_all&amp;#x27;&lt;/span&gt;: &lt;span class=&quot;literal&quot;&gt;True&lt;/span&gt;,   &lt;span class=&quot;comment&quot;&gt;# Whether to use all features.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;string&quot;&gt;&amp;#x27;valid_ratio&amp;#x27;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;0.2&lt;/span&gt;,   &lt;span class=&quot;comment&quot;&gt;# validation_size = train_size * valid_ratio&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;string&quot;&gt;&amp;#x27;n_epochs&amp;#x27;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;3000&lt;/span&gt;,     &lt;span class=&quot;comment&quot;&gt;# Number of epochs.            &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;string&quot;&gt;&amp;#x27;batch_size&amp;#x27;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;256&lt;/span&gt;, &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;string&quot;&gt;&amp;#x27;learning_rate&amp;#x27;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;1e-5&lt;/span&gt;,              &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;string&quot;&gt;&amp;#x27;early_stop&amp;#x27;&lt;/span&gt;: &lt;span class=&quot;number&quot;&gt;400&lt;/span&gt;,    &lt;span class=&quot;comment&quot;&gt;# If model has not improved for this many consecutive epochs, stop training.     &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;string&quot;&gt;&amp;#x27;save_path&amp;#x27;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&amp;#x27;./models/model.ckpt&amp;#x27;&lt;/span&gt;  &lt;span class=&quot;comment&quot;&gt;# Your model will be saved here.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</span><br><span class="line">&lt;p&gt;“””<span class="comment"># Dataloader&lt;br&gt;Read data from files and set up training, validation, and testing sets. You do not need to modify this part.&lt;br&gt;“””&lt;/p&gt;</span></span><br><span class="line">&lt;h1 id=&quot;Set-seed-for-reproducibility&quot;&gt;&lt;a href=&quot;#Set-seed-for-reproducibility&quot; class=&quot;headerlink&quot; title=&quot;Set seed for reproducibility&quot;&gt;&lt;/a&gt;Set seed for reproducibility&lt;/h1&gt;&lt;p&gt;same_seed (config [‘seed’])&lt;/p&gt;</span><br><span class="line">&lt;h1 id=&quot;train-data-size-2699-x-118-id-37-states-16-features-x-5-days&quot;&gt;&lt;a href=&quot;#train-data-size-2699-x-118-id-37-states-16-features-x-5-days&quot; class=&quot;headerlink&quot; title=&quot;train_data size: 2699 x 118 (id + 37 states + 16 features x 5 days)&quot;&gt;&lt;/a&gt;train_data size: 2699 x 118 (id + 37 states + 16 features x 5 days)&lt;/h1&gt;&lt;h1 id=&quot;test-data-size-1078-x-117-without-last-day’s-positive-rate&quot;&gt;&lt;a href=&quot;#test-data-size-1078-x-117-without-last-day’s-positive-rate&quot; class=&quot;headerlink&quot; title=&quot;test_data size: 1078 x 117 (without last day’s positive rate)&quot;&gt;&lt;/a&gt;test_data size: 1078 x 117 (without last day’s positive rate)&lt;/h1&gt;&lt;p&gt;train_data, test_data = pd.read_csv (‘./covid.train.csv’).values, pd.read_csv (‘./covid.test.csv’).values&lt;br&gt;train_data, valid_data = train_valid_split (train_data, config [‘valid_ratio’], config [‘seed’])&lt;/p&gt;</span><br><span class="line">&lt;h1 id=&quot;Print-out-the-data-size&quot;&gt;&lt;a href=&quot;#Print-out-the-data-size&quot; class=&quot;headerlink&quot; title=&quot;Print out the data size.&quot;&gt;&lt;/a&gt;Print out the data size.&lt;/h1&gt;&lt;p&gt;print (f”””train_data size: &#123;train_data.shape&#125;&lt;br&gt;valid_data size: &#123;valid_data.shape&#125;&lt;br&gt;test_data size: &#123;test_data.shape&#125;”””)&lt;/p&gt;</span><br><span class="line">&lt;h1 id=&quot;Select-features&quot;&gt;&lt;a href=&quot;#Select-features&quot; class=&quot;headerlink&quot; title=&quot;Select features&quot;&gt;&lt;/a&gt;Select features&lt;/h1&gt;&lt;p&gt;x_train, x_valid, x_test, y_train, y_valid = select_feat (train_data, valid_data, test_data, config [‘select_all’])&lt;/p&gt;</span><br><span class="line">&lt;h1 id=&quot;Print-out-the-number-of-features&quot;&gt;&lt;a href=&quot;#Print-out-the-number-of-features&quot; class=&quot;headerlink&quot; title=&quot;Print out the number of features.&quot;&gt;&lt;/a&gt;Print out the number of features.&lt;/h1&gt;&lt;p&gt;print (f’number of features: &#123;x_train.shape [1]&#125;’)&lt;/p&gt;</span><br><span class="line">&lt;p&gt;train_dataset, valid_dataset, test_dataset = COVID19Dataset (x_train, y_train), \&lt;br&gt;                                            COVID19Dataset (x_valid, y_valid), \&lt;br&gt;                                            COVID19Dataset (x_test)&lt;/p&gt;</span><br><span class="line">&lt;h1 id=&quot;Pytorch-data-loader-loads-pytorch-dataset-into-batches&quot;&gt;&lt;a href=&quot;#Pytorch-data-loader-loads-pytorch-dataset-into-batches&quot; class=&quot;headerlink&quot; title=&quot;Pytorch data loader loads pytorch dataset into batches.&quot;&gt;&lt;/a&gt;Pytorch data loader loads pytorch dataset into batches.&lt;/h1&gt;&lt;p&gt;train_loader = DataLoader (train_dataset, batch_size=config [‘batch_size’], shuffle=True, pin_memory=True)&lt;br&gt;valid_loader = DataLoader (valid_dataset, batch_size=config [‘batch_size’], shuffle=True, pin_memory=True)&lt;br&gt;test_loader = DataLoader (test_dataset, batch_size=config [‘batch_size’], shuffle=False, pin_memory=True)&lt;/p&gt;</span><br></pre></td></tr></table></figure>
<h3 id="Start-training"><a href="#Start-training" class="headerlink" title="Start training!"></a>Start training!</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">model = My_Model (input_dim=x_train.shape [<span class="number">1</span>]).to (device) <span class="comment"># put your model and data on the same computation device.</span></span><br><span class="line">trainer (train_loader, valid_loader, model, config, device)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="Plot-learning-curves-with-tensorboard-optional"><a href="#Plot-learning-curves-with-tensorboard-optional" class="headerlink" title="Plot learning curves with tensorboard (optional)"></a>Plot learning curves with <code>tensorboard</code> (optional)</h3><h3 id="Testing"><a href="#Testing" class="headerlink" title="Testing"></a>Testing</h3><p>The predictions of your model on testing set will be stored at <code>pred.csv</code>.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_pred</span> (<span class="params">preds, file</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; Save predictions to specified file &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span> (file, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">        writer = csv.writer (fp)</span><br><span class="line">        writer.writerow ([<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;tested_positive&#x27;</span>])</span><br><span class="line">        <span class="keyword">for</span> i, p <span class="keyword">in</span> <span class="built_in">enumerate</span> (preds):</span><br><span class="line">            writer.writerow ([i, p])</span><br><span class="line"></span><br><span class="line">model = My_Model (input_dim=x_train.shape [<span class="number">1</span>]).to (device)</span><br><span class="line">model.load_state_dict (torch.load (config [<span class="string">&#x27;save_path&#x27;</span>]))</span><br><span class="line">preds = predict (test_loader, model, device) </span><br><span class="line">save_pred (preds, <span class="string">&#x27;pred.csv&#x27;</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>This notebook uses code written by Heng-Jui Chang @ NTUEE (<a target="_blank" rel="noopener" href="https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb">https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb</a>)</p>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/02/17/bishe-3/" rel="prev" title="bishe-3">
                  <i class="fa fa-chevron-left"></i> bishe-3
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/07/05/baseline-1-logger/" rel="next" title="baseline-1-logger">
                  baseline-1-logger <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>







<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Nathan Wang</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 強力驅動
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  



<script>
if (document.querySelectorAll('.pdf-container').length) {
  NexT.utils.getScript('https://cdn.jsdelivr.net/npm/pdfobject@2.2.4/pdfobject.min.js', () => {
    document.querySelectorAll('.pdf-container').forEach(element => {
      PDFObject.embed(element.dataset.target, element, {
        pdfOpenParams: {
          navpanes : 0,
          toolbar  : 0,
          statusbar: 0,
          pagemode : 'thumbs',
          view     : 'FitH'
        },
        PDFJS_URL: '/lib/pdf/web/viewer.html',
        height   : element.dataset.height
      });
    });
  }, window.PDFObject);
}
</script>



  




  


</body>
</html>
